{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9e8719",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74874a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from pymed import PubMed\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , LSTM ,Embedding, Input, SpatialDropout1D, Flatten, SimpleRNN, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee5d76",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad27a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a PubMed object that GraphQL can use to query\n",
    "# Note that the parameters are not required but kindly requested by PubMed Central\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/tools/developers/\n",
    "pubmed = PubMed(tool=\"MyTool\", email=\"my@email.address\")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Create a GraphQL query in plain text\n",
    "conversations_keywords = ['symptoms', 'presence of', 'sign off', 'suggestion', 'clue',  'hint of']\n",
    "diseases = ['diabetes', 'hypertension', 'arthritis', 'tuberculosis', 'pneumonia']\n",
    "            #'peptic ulcer', 'gastroenteritis']\n",
    "for disease in diseases:\n",
    "    for keyword in conversations_keywords:\n",
    "        query = '('+ disease +'[Title]) AND ('+ keyword + '[Text Word])'\n",
    "        print('Excuting query: ' + query)\n",
    "        \n",
    "        # Execute the query against the API\n",
    "        results = pubmed.query(query, max_results=2000)\n",
    "\n",
    "        abstracts = []\n",
    "        keywords = []\n",
    "        \n",
    "        # Loop over the retrieved articles\n",
    "        for article in results:\n",
    "            # Extract and format information from the article\n",
    "            article_id = article.pubmed_id\n",
    "            title = article.title\n",
    "            publication_date = article.publication_date\n",
    "            abstract = article.abstract\n",
    "            abstracts.append((abstract, disease))\n",
    "\n",
    "abstracts_df = pd.DataFrame(abstracts)\n",
    "abstracts_df.to_csv('disease_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file that was created\n",
    "disease_data = pd.read_csv('disease_data.csv')\n",
    "disease_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07433fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b598c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_data.columns= ['abstract' , 'disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset based on disease\n",
    "print(disease_data['disease'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the disease words from abstract data to prevent overfitting.\n",
    "\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('tuberculosis','')\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('arthritis','')\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('diabetes','')\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('peptic','')\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('ulcer','')\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('gastroenteritis','')\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('pneumonia','')\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('diabetes','')\n",
    "\n",
    "disease_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09831912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the na's\n",
    "disease_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations and numbers\n",
    "disease_data[\"abstract\"] = disease_data[\"abstract\"].str.replace('[^a-zA-Z\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmanization function creattion\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typecasting the abstract column to string\n",
    "disease_data[\"abstract\"] = disease_data[\"abstract\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8de48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the lemmanization function to abstract column\n",
    "disease_data['abstract'] = disease_data.abstract.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3eaee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disease_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412033bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_data['abstract'] = disease_data['abstract'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test dataset (80/20)\n",
    "\n",
    "train, test = train_test_split(disease_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d767b0",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to vectorize, applying Tfid transformation and Naive Bayes\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('nb', MultinomialNB())])\n",
    "nb = nb.fit(train.abstract, train.disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy\n",
    "\n",
    "y_pred = nb.predict(test.abstract)\n",
    "print(accuracy_score(test.disease,y_pred)) # 0.8368491921005387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "\n",
    "print(classification_report(test.disease,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "s = sns.heatmap(confusion_matrix(test.disease,y_pred),xticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"] ,yticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"], annot=True, fmt='.4g' )\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58853d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on some user generated symptoms\n",
    "\n",
    "p = nb.predict(['feelings of sickness or weakness, weight loss, fever, \\\n",
    "  and night sweats. coughing, chest pain, and the coughing up of blood.', 'I get really tired and have vision problem',\n",
    "'Patient: Doctor, I’ve headache since yesterday evening.  Doctor: Have you taken any medicine so far?\\ Patient: Saridon, but the headache hasn’t disappeared. \\ Doctor: You’ve a running nose. Looks like your headacheis a result of\\ sinus infection, and not the regular one that results from anxiety and fatigue. Lemme check.\\  (The doctor checks the patient thoroughly.)\\ Doctor: It’s quite clear that the infection in your sinus is the reason for your headache. I’ll prescribe an antibiotic to clear the infection and a pain reliever to relieve the pain.\\ Patient: Thank you, doctor.'])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to vectorize, applying Tfid transformation and Linear Support Vector Classification\n",
    "\n",
    "svc = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('svc', svm.LinearSVC())])\n",
    "svc = svc.fit(train.abstract, train.disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy\n",
    "\n",
    "y_pred = svc.predict(test.abstract)\n",
    "print(accuracy_score(test.disease,y_pred)) # 0.9429982046678635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test.disease,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "s = sns.heatmap(confusion_matrix(test.disease,y_pred),xticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"] ,yticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"], annot=True, fmt='.4g' )\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on some user generated symptoms\n",
    "\n",
    "p = svc.predict(['feelings of sickness or weakness, weight loss, fever, \\\n",
    "  and night sweats. coughing, chest pain, and the coughing up of blood.', 'I get really tired and have vision problem',\n",
    "'Patient: Doctor, I’ve headache since yesterday evening.  Doctor: Have you taken any medicine so far?\\ Patient: Saridon, but the headache hasn’t disappeared. \\ Doctor: You’ve a running nose. Looks like your headacheis a result of\\ sinus infection, and not the regular one that results from anxiety and fatigue. Lemme check.\\  (The doctor checks the patient thoroughly.)\\ Doctor: It’s quite clear that the infection in your sinus is the reason for your headache. I’ll prescribe an antibiotic to clear the infection and a pain reliever to relieve the pain.\\ Patient: Thank you, doctor.'])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to vectorize, applying Tfid transformation and Logistic Regression\n",
    "\n",
    "lr  = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('lr', LogisticRegression())])\n",
    "lr = lr.fit(train.abstract, train.disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy\n",
    "\n",
    "y_pred = lr.predict(test.abstract)\n",
    "print(accuracy_score(test.disease,y_pred)) # 0.9355924596050269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test.disease,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "s = sns.heatmap(confusion_matrix(test.disease,y_pred),xticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"] ,yticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"], annot=True, fmt='.4g' )\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8766a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lr.predict(['Feelings of sickness or weakness, weight loss, fever, and night sweats', \n",
    "                'i feel thirsty most of the time, i have experienced weight loss, increase \\\n",
    "                in  appetite, blurry vision, numb, tingling hands', \n",
    "                'I have burning stomach, heartburn and nausea from last few days',\n",
    "                'i feel pain and stiffness in my knees, I cannot move my knees much'])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to vectorize, applying Tfid transformation and Random Forest\n",
    "\n",
    "rf  = Pipeline([('vect', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),('rf', RandomForestClassifier())])\n",
    "rf = rf.fit(train.abstract, train.disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcafb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(test.abstract)\n",
    "print(accuracy_score(test.disease,y_pred)) # 0.9196588868940754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a338d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test.disease,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "s = sns.heatmap(confusion_matrix(test.disease,y_pred),xticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"] ,yticklabels=[\"arthritis\", \"diabetes\", \"gastroenteritis\", \"hypertension\", \"peptic ulcer\", \"pneumonia\", \"tuberculosis\"], annot=True, fmt='.4g' )\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on some user generated symptoms\n",
    "\n",
    "p = rf.predict(['feelings of sickness or weakness, weight loss, fever, \\\n",
    "  and night sweats. coughing, chest pain, and the coughing up of blood.', 'I get really tired and have vision problem',\n",
    "'Patient: Doctor, I’ve headache since yesterday evening.  Doctor: Have you taken any medicine so far?\\ Patient: Saridon, but the headache hasn’t disappeared. \\ Doctor: You’ve a running nose. Looks like your headacheis a result of\\ sinus infection, and not the regular one that results from anxiety and fatigue. Lemme check.\\  (The doctor checks the patient thoroughly.)\\ Doctor: It’s quite clear that the infection in your sinus is the reason for your headache. I’ll prescribe an antibiotic to clear the infection and a pain reliever to relieve the pain.\\ Patient: Thank you, doctor.'])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e743aa3",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "#Using the raw data to clean and tokenize again.\n",
    "\n",
    "disease_data = disease_data.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "disease_data['abstract'] = disease_data['abstract'].apply(clean_text)\n",
    "disease_data['abstract'] = disease_data['abstract'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb255e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using different tokenizer for Neural Networks\n",
    "\n",
    "MAX_NB_WORDS = 5000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 50\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(disease_data['abstract'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269166c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(disease_data['abstract'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(disease_data['disease']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ea5df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_rnn_model(X_train, X_test, Y_train, Y_test):\n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    rnn_model.add(SpatialDropout1D(0.2))\n",
    "    rnn_model.add(Bidirectional(LSTM(250, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "    rnn_model.add(Bidirectional(LSTM(250, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    rnn_model.add(Dense(7, activation='softmax'))\n",
    "    rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 64\n",
    "\n",
    "    history = rnn_model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    accr = rnn_model.evaluate(X_test,Y_test)\n",
    "    print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    return rnn_model, accr[1]\n",
    "\n",
    "rnn_model = run_rnn_model(X_train, X_test, Y_train, Y_test)[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1714c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = rnn_model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "\n",
    "Y_pred = rnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212728a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on some user generated symptoms\n",
    "\n",
    "new_complaint = ['Feelings of sickness or weakness, weight loss, fever, and night sweats', \n",
    "                'i feel thirsty most of the time, i have experienced weight loss, increase \\\n",
    "                in  appetite, blurry vision, numb, tingling hands', \n",
    "                'I have burning stomach, heartburn and nausea from last few days',\n",
    "                'i feel pain and stiffness in my knees, I cannot move my knees much'] \n",
    "seq = tokenizer.texts_to_sequences(new_complaint)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = rnn_model.predict(padded)\n",
    "labels = ['arthritis', 'diabetes', 'gastroenteritis', 'hypertension', 'peptic ulcer', 'pneumonia', 'tuberculosis']\n",
    "for p in pred:\n",
    "  print(p, np.argmax(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e54f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 5000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 50\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(disease_data['abstract'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(disease_data['abstract'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(disease_data['disease']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e55da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn_model(X_train, X_test, y_train, y_test):\n",
    "    # Building the CNN Model\n",
    "    cnn_model = Sequential()      # initilaizing the Sequential nature for CNN model\n",
    "    # Adding the embedding layer which will take in maximum of 450 words as input and provide a 32 dimensional output of those words which belong in the top_words dictionary\n",
    "    cnn_model.add(Embedding(MAX_NB_WORDS, 64, input_length=X.shape[1]))\n",
    "    cnn_model.add(Conv1D(264, 3, padding='same', activation='relu'))\n",
    "    cnn_model.add(Conv1D(232, kernel_size=3, activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D())\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(250, activation='relu'))\n",
    "    cnn_model.add(Dense(7, activation='softmax'))\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    cnn_model.summary()\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 64\n",
    "\n",
    "    history = cnn_model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    accr = cnn_model.evaluate(X_test,Y_test)\n",
    "    print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    return cnn_model, accr[1]\n",
    "\n",
    "cnn_model = run_cnn_model(X_train, X_test, Y_train, Y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1511cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = cnn_model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "\n",
    "Y_pred = cnn_model.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on some user generated symptoms\n",
    "\n",
    "new_complaint = ['Feelings of sickness or weakness, weight loss, fever, and night sweats', \n",
    "                'i feel thirsty most of the time, i have experienced weight loss, increase \\\n",
    "                in  appetite, blurry vision, numb, tingling hands', \n",
    "                'I have burning stomach, heartburn and nausea from last few days',\n",
    "                'i feel pain and stiffness in my knees, I cannot move my knees much'] \n",
    "seq = tokenizer.texts_to_sequences(new_complaint)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = cnn_model.predict(padded)\n",
    "labels = ['arthritis', 'diabetes', 'gastroenteritis', 'hypertension', 'peptic ulcer', 'pneumonia', 'tuberculosis']\n",
    "for p in pred:\n",
    "  print(p, labels[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0decb70",
   "metadata": {},
   "source": [
    "### -------- ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
